{
 "cells": [
  {
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "# tf\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# set working directory\n",
    "import os\n",
    "path = \"/home/mriveralanas/projects/quora/\"\n",
    "os.chdir(path)\n",
    "\n",
    "# user modules\n",
    "import src.data.process_data as process_data\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 1
  },
  {
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# !pip install -q tensorflow-hub\n",
    "# !pip install -q tensorflow-datasets\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Version:  2.0.0\nEager mode:  True\nHub version:  0.7.0\nGPU is NOT AVAILABLE\n"
    }
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "source": [
    "# load train.csv and split into training, validation and test \n",
    "train_data, validation_data, test_data = process_data.train_split(process_data.retrieve_training())"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Examples:\n    Total: 1306122\n    Positive: 80810 (6.19% of total)\n\n"
    }
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "source": [
    "\n",
    "# show example from train data \n",
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "\n",
    "# train examples --> inputs\n",
    "train_examples_batch = tf.reshape(train_examples_batch, [10,])\n",
    "train_examples_batch"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=21, shape=(10,), dtype=string, numpy=\narray([b\"Am I alone in feeling like Quora doesn't provide enough space for context in personal and/or introspective questions anymore?\",\n       b'Do elderly people feel or know when there getting ready to pass on?',\n       b'What skills should I learn as a physiotherapist?',\n       b'What are some hoaxes people still belive are true?',\n       b'What percentage of IPOs have negative earnings?',\n       b'What can I do to help my boyfriend deal with childhood rape?',\n       b'Why is \"The Black Cat\" considered a goth themed story?',\n       b'How can I check Skillselect Mailbox?',\n       b'Why are women more able to get pregnant easier the younger they are?',\n       b'Why are some Americans obsessed with their guns?'], dtype=object)>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "source": [
    "# train examples --> labels\n",
    "train_examples_batch = tf.reshape(train_labels_batch, [10,])\n",
    "train_examples_batch"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=23, shape=(10,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 7
  },
  {
   "source": [
    "# TF Hub embeddings\n",
    "gnews = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "wiki = \"https://tfhub.dev/google/Wiki-words-500-with-normalization/2\"\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 8
  },
  {
   "source": [
    "hub_layer = hub.KerasLayer(gnews, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 9
  },
  {
   "source": [
    "hub_layer"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow_hub.keras_layer.KerasLayer at 0x7fad82c08550>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop out layer"
   ]
  },
  {
   "source": [
    "# building full model \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    " \n",
    "# specify layers\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nkeras_layer (KerasLayer)     (None, 20)                400020    \n_________________________________________________________________\ndense (Dense)                (None, 16)                336       \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 400,373\nTrainable params: 400,373\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "source": [
    "# model compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 12
  },
  {
   "source": [
    "# train model\n",
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_data.batch(512),\n",
    "                    verbose=1)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n1633/1633 [==============================] - 29s 18ms/step - loss: 0.1757 - tp: 14850.0000 - fp: 18326.0000 - tn: 765873.0000 - fn: 36868.0000 - accuracy: 0.9340 - precision: 0.4476 - recall: 0.2871 - auc: 0.8729 - val_loss: 0.0000e+00 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\nEpoch 2/20\n1633/1633 [==============================] - 23s 14ms/step - loss: 0.1226 - tp: 22891.0000 - fp: 11299.0000 - tn: 772900.0000 - fn: 28827.0000 - accuracy: 0.9520 - precision: 0.6695 - recall: 0.4426 - auc: 0.9425 - val_loss: 0.1256 - val_tp: 5589.0000 - val_fp: 2863.0000 - val_tn: 193187.0000 - val_fn: 7341.0000 - val_accuracy: 0.9512 - val_precision: 0.6613 - val_recall: 0.4323 - val_auc: 0.9378\nEpoch 3/20\n1633/1633 [==============================] - 22s 14ms/step - loss: 0.1162 - tp: 24700.0000 - fp: 11382.0000 - tn: 772817.0000 - fn: 27018.0000 - accuracy: 0.9541 - precision: 0.6846 - recall: 0.4776 - auc: 0.9495 - val_loss: 0.1242 - val_tp: 6281.0000 - val_fp: 3499.0000 - val_tn: 192551.0000 - val_fn: 6649.0000 - val_accuracy: 0.9514 - val_precision: 0.6422 - val_recall: 0.4858 - val_auc: 0.9399\nEpoch 4/20\n1633/1633 [==============================] - 22s 13ms/step - loss: 0.1126 - tp: 25732.0000 - fp: 11369.0000 - tn: 772830.0000 - fn: 25986.0000 - accuracy: 0.9553 - precision: 0.6936 - recall: 0.4975 - auc: 0.9534 - val_loss: 0.1238 - val_tp: 6104.0000 - val_fp: 3194.0000 - val_tn: 192856.0000 - val_fn: 6826.0000 - val_accuracy: 0.9521 - val_precision: 0.6565 - val_recall: 0.4721 - val_auc: 0.9398\nEpoch 5/20\n1633/1633 [==============================] - 18s 11ms/step - loss: 0.1099 - tp: 26348.0000 - fp: 11235.0000 - tn: 772964.0000 - fn: 25370.0000 - accuracy: 0.9562 - precision: 0.7011 - recall: 0.5095 - auc: 0.9559 - val_loss: 0.1241 - val_tp: 6453.0000 - val_fp: 3509.0000 - val_tn: 192541.0000 - val_fn: 6477.0000 - val_accuracy: 0.9522 - val_precision: 0.6478 - val_recall: 0.4991 - val_auc: 0.9399\nEpoch 6/20\n1633/1633 [==============================] - 21s 13ms/step - loss: 0.1076 - tp: 27066.0000 - fp: 11113.0000 - tn: 773086.0000 - fn: 24652.0000 - accuracy: 0.9572 - precision: 0.7089 - recall: 0.5233 - auc: 0.9579 - val_loss: 0.1246 - val_tp: 6065.0000 - val_fp: 3044.0000 - val_tn: 193006.0000 - val_fn: 6865.0000 - val_accuracy: 0.9526 - val_precision: 0.6658 - val_recall: 0.4691 - val_auc: 0.9384\nEpoch 7/20\n1633/1633 [==============================] - 24s 15ms/step - loss: 0.1056 - tp: 27548.0000 - fp: 10989.0000 - tn: 773210.0000 - fn: 24170.0000 - accuracy: 0.9579 - precision: 0.7148 - recall: 0.5327 - auc: 0.9597 - val_loss: 0.1256 - val_tp: 5955.0000 - val_fp: 2929.0000 - val_tn: 193121.0000 - val_fn: 6975.0000 - val_accuracy: 0.9526 - val_precision: 0.6703 - val_recall: 0.4606 - val_auc: 0.9373\nEpoch 8/20\n1633/1633 [==============================] - 23s 14ms/step - loss: 0.1037 - tp: 28088.0000 - fp: 10860.0000 - tn: 773339.0000 - fn: 23630.0000 - accuracy: 0.9587 - precision: 0.7212 - recall: 0.5431 - auc: 0.9613 - val_loss: 0.1260 - val_tp: 6463.0000 - val_fp: 3545.0000 - val_tn: 192505.0000 - val_fn: 6467.0000 - val_accuracy: 0.9521 - val_precision: 0.6458 - val_recall: 0.4998 - val_auc: 0.9373\nEpoch 9/20\n1633/1633 [==============================] - 22s 13ms/step - loss: 0.1019 - tp: 28571.0000 - fp: 10742.0000 - tn: 773457.0000 - fn: 23147.0000 - accuracy: 0.9595 - precision: 0.7268 - recall: 0.5524 - auc: 0.9628 - val_loss: 0.1277 - val_tp: 6114.0000 - val_fp: 3132.0000 - val_tn: 192918.0000 - val_fn: 6816.0000 - val_accuracy: 0.9524 - val_precision: 0.6613 - val_recall: 0.4729 - val_auc: 0.9357\nEpoch 10/20\n1633/1633 [==============================] - 18s 11ms/step - loss: 0.1002 - tp: 29030.0000 - fp: 10610.0000 - tn: 773589.0000 - fn: 22688.0000 - accuracy: 0.9602 - precision: 0.7323 - recall: 0.5613 - auc: 0.9641 - val_loss: 0.1288 - val_tp: 6165.0000 - val_fp: 3201.0000 - val_tn: 192849.0000 - val_fn: 6765.0000 - val_accuracy: 0.9523 - val_precision: 0.6582 - val_recall: 0.4768 - val_auc: 0.9344\nEpoch 11/20\n1633/1633 [==============================] - 21s 13ms/step - loss: 0.0986 - tp: 29465.0000 - fp: 10488.0000 - tn: 773711.0000 - fn: 22253.0000 - accuracy: 0.9608 - precision: 0.7375 - recall: 0.5697 - auc: 0.9654 - val_loss: 0.1292 - val_tp: 6581.0000 - val_fp: 3759.0000 - val_tn: 192291.0000 - val_fn: 6349.0000 - val_accuracy: 0.9516 - val_precision: 0.6365 - val_recall: 0.5090 - val_auc: 0.9349\nEpoch 12/20\n1633/1633 [==============================] - 24s 15ms/step - loss: 0.0969 - tp: 29926.0000 - fp: 10278.0000 - tn: 773921.0000 - fn: 21792.0000 - accuracy: 0.9616 - precision: 0.7444 - recall: 0.5786 - auc: 0.9666 - val_loss: 0.1305 - val_tp: 6406.0000 - val_fp: 3573.0000 - val_tn: 192477.0000 - val_fn: 6524.0000 - val_accuracy: 0.9517 - val_precision: 0.6419 - val_recall: 0.4954 - val_auc: 0.9335\nEpoch 13/20\n1633/1633 [==============================] - 25s 15ms/step - loss: 0.0952 - tp: 30373.0000 - fp: 10179.0000 - tn: 774020.0000 - fn: 21345.0000 - accuracy: 0.9623 - precision: 0.7490 - recall: 0.5873 - auc: 0.9677 - val_loss: 0.1323 - val_tp: 6139.0000 - val_fp: 3300.0000 - val_tn: 192750.0000 - val_fn: 6791.0000 - val_accuracy: 0.9517 - val_precision: 0.6504 - val_recall: 0.4748 - val_auc: 0.9314\nEpoch 14/20\n1633/1633 [==============================] - 16s 10ms/step - loss: 0.0937 - tp: 30844.0000 - fp: 10027.0000 - tn: 774172.0000 - fn: 20874.0000 - accuracy: 0.9630 - precision: 0.7547 - recall: 0.5964 - auc: 0.9688 - val_loss: 0.1338 - val_tp: 6430.0000 - val_fp: 3665.0000 - val_tn: 192385.0000 - val_fn: 6500.0000 - val_accuracy: 0.9514 - val_precision: 0.6369 - val_recall: 0.4973 - val_auc: 0.9306\nEpoch 15/20\n1633/1633 [==============================] - 14s 9ms/step - loss: 0.0920 - tp: 31303.0000 - fp: 9880.0000 - tn: 774319.0000 - fn: 20415.0000 - accuracy: 0.9638 - precision: 0.7601 - recall: 0.6053 - auc: 0.9699 - val_loss: 0.1356 - val_tp: 6083.0000 - val_fp: 3295.0000 - val_tn: 192755.0000 - val_fn: 6847.0000 - val_accuracy: 0.9515 - val_precision: 0.6486 - val_recall: 0.4705 - val_auc: 0.9287\nEpoch 16/20\n1633/1633 [==============================] - 14s 9ms/step - loss: 0.0904 - tp: 31715.0000 - fp: 9732.0000 - tn: 774467.0000 - fn: 20003.0000 - accuracy: 0.9644 - precision: 0.7652 - recall: 0.6132 - auc: 0.9709 - val_loss: 0.1372 - val_tp: 6466.0000 - val_fp: 3778.0000 - val_tn: 192272.0000 - val_fn: 6464.0000 - val_accuracy: 0.9510 - val_precision: 0.6312 - val_recall: 0.5001 - val_auc: 0.9284\nEpoch 17/20\n1633/1633 [==============================] - 14s 9ms/step - loss: 0.0887 - tp: 32176.0000 - fp: 9603.0000 - tn: 774596.0000 - fn: 19542.0000 - accuracy: 0.9651 - precision: 0.7701 - recall: 0.6221 - auc: 0.9720 - val_loss: 0.1385 - val_tp: 6563.0000 - val_fp: 4059.0000 - val_tn: 191991.0000 - val_fn: 6367.0000 - val_accuracy: 0.9501 - val_precision: 0.6179 - val_recall: 0.5076 - val_auc: 0.9278\nEpoch 18/20\n1633/1633 [==============================] - 14s 9ms/step - loss: 0.0871 - tp: 32585.0000 - fp: 9401.0000 - tn: 774798.0000 - fn: 19133.0000 - accuracy: 0.9659 - precision: 0.7761 - recall: 0.6301 - auc: 0.9729 - val_loss: 0.1407 - val_tp: 6654.0000 - val_fp: 4296.0000 - val_tn: 191754.0000 - val_fn: 6276.0000 - val_accuracy: 0.9494 - val_precision: 0.6077 - val_recall: 0.5146 - val_auc: 0.9263\nEpoch 19/20\n1633/1633 [==============================] - 14s 9ms/step - loss: 0.0854 - tp: 33092.0000 - fp: 9271.0000 - tn: 774928.0000 - fn: 18626.0000 - accuracy: 0.9666 - precision: 0.7812 - recall: 0.6399 - auc: 0.9739 - val_loss: 0.1428 - val_tp: 6343.0000 - val_fp: 3838.0000 - val_tn: 192212.0000 - val_fn: 6587.0000 - val_accuracy: 0.9501 - val_precision: 0.6230 - val_recall: 0.4906 - val_auc: 0.9242\nEpoch 20/20\n1633/1633 [==============================] - 16s 10ms/step - loss: 0.0838 - tp: 33568.0000 - fp: 9133.0000 - tn: 775066.0000 - fn: 18150.0000 - accuracy: 0.9674 - precision: 0.7861 - recall: 0.6491 - auc: 0.9748 - val_loss: 0.1454 - val_tp: 6013.0000 - val_fp: 3518.0000 - val_tn: 192532.0000 - val_fn: 6917.0000 - val_accuracy: 0.9501 - val_precision: 0.6309 - val_recall: 0.4650 - val_auc: 0.9220\n"
    }
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "source": [
    "history"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fad7b080668>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "source": [
    "# evaluate \n",
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "511/511 - 3s - loss: 0.1419 - tp: 7715.0000 - fp: 4242.0000 - tn: 240821.0000 - fn: 8447.0000 - accuracy: 0.9514 - precision: 0.6452 - recall: 0.4774 - auc: 0.9242\nloss: 0.142\ntp: 7715.000\nfp: 4242.000\ntn: 240821.000\nfn: 8447.000\naccuracy: 0.951\nprecision: 0.645\nrecall: 0.477\nauc: 0.924\n"
    }
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}