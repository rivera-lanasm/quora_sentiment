{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "# set working directory to parent\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# import packages\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorboard import notebook\n",
    "%load_ext tensorboard\n",
    "\n",
    "from src.data import process_data \n",
    "\n",
    "# check tf version\n",
    "print(\"TF Version: \", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Insinceere Question Classification \n",
    "\n",
    "[Kaggle Competition](https://www.kaggle.com/c/quora-insincere-questions-classification/notebooks)\n",
    "\n",
    "This project is meant to help me explore some of the theory behind neural network models, as well as the methodologies behind designing their architectures and training them. \n",
    "\n",
    "Here is an excerpt from the problem statement from the competition site:\n",
    "\n",
    "\"An existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world...**A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers**... Help Quora uphold their policy of “Be Nice, Be Respectful” and continue to be a place for sharing and growing the world’s knowledge.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "\n",
    "All of the approaches in this notebook will involve neural networks written in the Tensorflow 2 framework. In the table of contents is a list of approaches and methodologies that will be tested across the different models I implement, roughly in the order in which they appear in the pipeline. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approaching Imbalanced Data:\n",
    "\n",
    "The first thing you notice about this data set is the imbalance in class proportions. The size of the data set is about 1.3 million examples, of which only 6.2% are instances of \"insincere\" questions. Whether this proportion represents a good estimate of the 'true' distribution of classes or an anomolous sample is not so relevant as simply understanding how to model a classifier given class imbalance. \n",
    "\n",
    "\n",
    "Below I split the full data set into a training (80%) and test (20%) set. I use Sklearn's stratified sampling method to preserve the class proportions observed in the original data set in both train and test sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from S3\n",
    "# https://code.oursky.com/tensorflow-svm-image-classifications-engine/\n",
    "data = process_data.retrieve_training(bucket = \"quora-questions\", file_name = \"data/train.csv\")\n",
    "\n",
    "# Use a utility from sklearn to split and shuffle our dataset\n",
    "train_df, test_df = train_test_split(data, test_size=.2, random_state=42, stratify = data['target'].values)\n",
    "\n",
    "# Measure data imbalance in training and test set \n",
    "for k,v in {\"training set\":train_df, \"test set\":test_df}.items():\n",
    "    neg, pos = np.bincount(v['target'].values)\n",
    "    total = neg + pos\n",
    "    print('{}:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "        k,total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of sincere questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in train_df[train_df['target'] == 0]['question_text'][1:10]:\n",
    "    print(sent)\n",
    "    print(\"=====  Next  =======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of insincere questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in train_df[train_df['target'] == 1]['question_text'][1:10]:\n",
    "    print(sent)\n",
    "    print(\"=====  Next  =======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about data gathering processes in general, it's quite possible that phenomenon that 'naturally' display class imbalance empirically display balance, and vice versa. Knowing whether the imbalance is intrinsic or extrinsic is outside the scope of the problem here. Further, the generating process for processes, like sincere vs. insincere questions, can evolve over time as the user base or judgement standards of a platform like Quora evolves. Therefore, I try to read little into the fact that the classes display imbalance and focus on how to account for it in the context of a model.   \n",
    "\n",
    "Given highly imbalanced data, most learners will exhibit bias towards the majority class, and in more extreme cases even ignore the minority class altogether. From a probabalistic point of view, for the learner, this often proves logical because the prior probability of the majority group often outweighs the evidence. \n",
    "\n",
    "In [Survey on Deep Learning with Class Imbalance](https://link.springer.com/article/10.1186/s40537-019-0192-5) from Journal of Big Data, authors Johnson and Khoshgoftaar group methods for handling class imbalance into three categories. The first, data-level techniques, attempt to reduce imbalance through resampling methods. The second, algorithm-level methods, implement a cost or weight schema on the underlying learner. Hybrid approaches combine both sampling and weighting methods. \n",
    "\n",
    "\n",
    "https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758\n",
    "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "http://203.170.84.89/~idawis33/DataScienceLab/publication/IJCNN15.wang.final.pdf\n",
    "https://towardsdatascience.com/handling-imbalanced-data-4fb691e23fe9\n",
    "http://di.ulb.ac.be/map/adalpozz/pdf/Racing_unbalanced_IDEAL.pdf\n",
    "https://rikunert.com/SMOTE_explained\n",
    "\n",
    "\n",
    "**Resampling methods to test:**\n",
    "1. no resampling\n",
    "2. smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Cost functions & Evaluation\n",
    "\n",
    "\n",
    "notes on binary cross entropy \n",
    "Notes from [Michael Nielson's online NN guide](http://neuralnetworksanddeeplearning.com/chap3.html)\n",
    "\n",
    "http://www.jussihuotari.com/2018/01/17/why-loss-and-accuracy-metrics-conflict/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results: TensorBoard\n",
    "\n",
    "Evaluating and comparing the different model architechtures, hyperparameter combinations, and training strategies requires a suite of accuracy metrics in addition to the loss function used in the training process. \n",
    "\n",
    "Tensorboard offers a good interface for plotting these metrics at each training epoch for both training and testing data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('quora': conda)",
   "language": "python",
   "name": "python361064bitquoraconda9b0626ecaedd4d86b27b6bf9323516ef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
